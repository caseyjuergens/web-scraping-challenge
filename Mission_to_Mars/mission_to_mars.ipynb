{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/91.0.4472.101/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\casey\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101]\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of redscience page to be scraped\n",
    "red_url= 'https://redplanetscience.com/'\n",
    "browser.visit(red_url)\n",
    "html= browser.html\n",
    "soup= bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA Engineers Checking InSight's Weather Sensors\n"
     ]
    }
   ],
   "source": [
    "#scrape news title\n",
    "news_title= soup.find('div', class_='content_title').text\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An electronics issue is suspected to be preventing the sensors from sharing their data about Mars weather with the spacecraft.\n"
     ]
    }
   ],
   "source": [
    "#scrape paragraph text\n",
    "news_p= soup.find('div', class_='article_teaser_body').text\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of space image site to be scraped\n",
    "import time\n",
    "image_url= 'https://spaceimages-mars.com/'\n",
    "browser.visit(image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spaceimages-mars.com/image/featured/mars3.jpg\n"
     ]
    }
   ],
   "source": [
    "for x in range(1):\n",
    "    html=browser.html\n",
    "    soup= bs(html, 'html.parser')\n",
    "    link_button= soup.find('div', class_='floating_text_area')\n",
    "    browser.links.find_by_partial_text('FULL IMAGE')\n",
    "    \n",
    "    image_box=soup.find('a', class_=\"showimg fancybox-thumbs\")\n",
    "    pic_url=image_box['href']\n",
    "    \n",
    "    #print(pic_url)\n",
    "\n",
    "#put together url\n",
    "featured_image_url= image_url+pic_url\n",
    "print(featured_image_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mars - Earth Comparison</td>\n",
       "      <td>Mars</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diameter:</td>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Distance from Sun:</td>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                1                2\n",
       "0  Mars - Earth Comparison             Mars            Earth\n",
       "1                Diameter:         6,779 km        12,742 km\n",
       "2                    Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "3                   Moons:                2                1\n",
       "4       Distance from Sun:   227,943,824 km   149,598,262 km"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url of facts site\n",
    "facts_url='https://galaxyfacts-mars.com/'\n",
    "facts_table=pd.read_html(facts_url)\n",
    "table_df= facts_table[0]\n",
    "table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>0</th>\\n      <th>1</th>\\n      <th>2</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Mars - Earth Comparison</td>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Diameter:</td>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Distance from Sun:</td>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Length of Year:</td>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Temperature:</td>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts_table_html= table_df.to_html()\n",
    "facts_table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3>Cerberus Hemisphere Enhanced</h3>, <h3>Schiaparelli Hemisphere Enhanced</h3>, <h3>Syrtis Major Hemisphere Enhanced</h3>, <h3>Valles Marineris Hemisphere Enhanced</h3>]\n"
     ]
    }
   ],
   "source": [
    "#url of hemispheres site\n",
    "hemi_url='https://marshemispheres.com/'\n",
    "browser.visit(hemi_url)\n",
    "html= browser.html\n",
    "soup= bs(html, 'html.parser') \n",
    "hemis= soup.find_all('h3', limit=4)\n",
    "print(hemis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-80d762a0e13a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#get hemi name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mc_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#finding pic url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#find title cerberus, get pic url\n",
    "for x in range(1):\n",
    "    #start path to hemi full pic url\n",
    "    cerberus= soup.find_all('div', class_='item')\n",
    "    #print(cerberus)\n",
    "    \n",
    "    #click link\n",
    "    browser.links.find_by_partial_text('Cerberus Hemisphere Enhanced')\n",
    "    \n",
    "    html=browser.html\n",
    "    soup= bs(html, 'html.parser')\n",
    "    \n",
    "    #get hemi name\n",
    "    c_title=soup.find('h2', class_=\"title\").text\n",
    "    \n",
    "    #finding pic url\n",
    "    downloads= soup.find('div', class_='downloads')\n",
    "    li=downloads.find('li')\n",
    "    url=li.find('a')['href']\n",
    "    #print(url)\n",
    "    \n",
    "    #add full image url to original url\n",
    "    cerb_url= hemi_url+url\n",
    "    #print(cerb_url)\n",
    "    \n",
    "    #create dict of hemi name and url\n",
    "    hemi_dict={\n",
    "        \"title\": c_title,\n",
    "        \"url\": cerb_url\n",
    "    }\n",
    "    print(hemi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3046b50ff4c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#get hemi name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0ms_title\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#finding pic url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#reset browser\n",
    "hemi_url='https://marshemispheres.com/'\n",
    "browser.visit(hemi_url)\n",
    "html= browser.html\n",
    "soup= bs(html, 'html.parser') \n",
    "\n",
    "#find title schiaparelli, get pic url\n",
    "for x in range(2):\n",
    "    #start path to hemi full pic url\n",
    "    schia= soup.find_all('div', class_='item')\n",
    "    #print(schia)\n",
    "    \n",
    "    #click link\n",
    "    browser.links.find_by_partial_text('Schiaparelli Hemisphere Enhanced')\n",
    "    \n",
    "    html=browser.html\n",
    "    soup= bs(html, 'html.parser')\n",
    "    \n",
    "    #get hemi name\n",
    "    s_title=soup.find('h2', class_=\"title\").text\n",
    "    \n",
    "    #finding pic url\n",
    "    downloads= soup.find('div', class_='downloads')\n",
    "    li=downloads.find('li')\n",
    "    url=li.find('a')['href']\n",
    "    #print(url)\n",
    "    \n",
    "    #add full image url to original url\n",
    "    schia_url= hemi_url+url\n",
    "    #print(schia_url)\n",
    "    \n",
    "    #create dict of hemi name and url\n",
    "    hemi_dict[s_title]= schia_url\n",
    "    print(hemi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset browser\n",
    "hemi_url='https://marshemispheres.com/'\n",
    "browser.visit(hemi_url)\n",
    "html= browser.html\n",
    "soup= bs(html, 'html.parser') \n",
    "\n",
    "#find title syrtis major, get pic url\n",
    "for x in range(3):\n",
    "    #start path to hemi full pic url\n",
    "    syrtis= soup.find_all('div', class_='item')\n",
    "    #print(syrtis)\n",
    "    \n",
    "    #click link\n",
    "    browser.click_link_by_partial_text('Syrtis Major Hemisphere Enhanced')\n",
    "    \n",
    "    html=browser.html\n",
    "    soup= bs(html, 'html.parser')\n",
    "    \n",
    "    #get hemi name\n",
    "    syr_title=soup.find('h2', class_=\"title\").text\n",
    "    \n",
    "    #finding pic url\n",
    "    downloads= soup.find('div', class_='downloads')\n",
    "    li=downloads.find('li')\n",
    "    url=li.find('a')['href']\n",
    "    #print(url)\n",
    "    \n",
    "    #add full image url to original url\n",
    "    syrtis_url= hemi_url+url\n",
    "    #print(syrtis_url)\n",
    "    \n",
    "    #create dict of hemi name and url\n",
    "    hemi_dict[syr_title]= syrtis_url\n",
    "    print(hemi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset browser\n",
    "hemi_url='https://marshemispheres.com/'\n",
    "browser.visit(hemi_url)\n",
    "html= browser.html\n",
    "soup= bs(html, 'html.parser') \n",
    "\n",
    "#find title valles marineris, get pic url\n",
    "for x in range(4):\n",
    "    #start path to hemi full pic url\n",
    "    valles= soup.find_all('div', class_='item')\n",
    "    #print(valles)\n",
    "    \n",
    "    #click link\n",
    "    browser.click_link_by_partial_text('Valles Marineris Hemisphere Enhanced')\n",
    "    \n",
    "    html=browser.html\n",
    "    soup= bs(html, 'html.parser')\n",
    "    \n",
    "    #get hemi name\n",
    "    v_title=soup.find('h2', class_=\"title\").text\n",
    "    \n",
    "    #finding pic url\n",
    "    downloads= soup.find('div', class_='downloads')\n",
    "    li=downloads.find('li')\n",
    "    url=li.find('a')['href']\n",
    "    #print(url)\n",
    "    \n",
    "    #add full image url to original url\n",
    "    valles_url= hemi_url+url\n",
    "    #print(valles_url)\n",
    "    \n",
    "    #create dict of hemi name and url\n",
    "    hemi_dict[v_title]= valles_url\n",
    "    print(hemi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
